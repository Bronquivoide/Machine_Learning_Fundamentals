{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Regresión Lineal Múltiple en Scikit-learn**\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### **El problema de regresión lineal**\n",
        "\n",
        "La regresión lineal es un problema de aprendizaje supervisado que consiste en aprender una función continua con un conjunto de datos de entrenamiento, $D_{train}=\\{ \\vec{x} , f(\\vec{x})\\}$, en donde se quiere determinar qué función lineal se ajusta mejor a ellos, con el fin de predecir valores continuos usando esta herramienta.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Fundamentos de la regresión lineal**\n",
        "\n",
        "**Hiperplano y función de costo:**\n",
        "\n",
        "Dado el conjunto de entrenamiento $D_{train}=\\{ \\vec{x}_k , f(\\vec{x}_k)=y_k \\in \\mathbb{R}\\}_{k=1}^N$, buscamos el hiperplano que mejor se ajusta a estos datos. Dada una muestra de entrenamiento, un par $(\\vec{x}, f(\\vec{x}))$, el modelo es de la forma $\\hat{f}(\\vec{x}, \\vec{w})= w_0 + (∑ _{i=1}^d w_i x_i)$, en donde $\\vec{x} \\in \\mathbb{R}^d$ es el vector de características (vector columna), y $\\vec{w} \\in \\mathbb{R}^{d+1}$ el parámetro de pesos (también vector columna).\n",
        "\n",
        "Se toma la convención de definir $x_0 :=1$, tal que se reescriba el hiperplano como:\n",
        "\n",
        "$$\\hat{f}(\\vec{x}, \\vec{w}) = ∑ _{i=0}^d w_i x_i = \\vec{w}^T \\vec{x}\n",
        "$$\n",
        "\n",
        "Definimos la función de costo (MSE) como:\n",
        "\n",
        "$$\\mathcal{L}(\\vec{w})=\\frac{1}{N} \\sum _{k=1}^N [f(\\vec{x}_k) - \\hat{f}(\\vec{x}_k, \\vec{w})] ^2 = \\sum _{k=1}^N [f(\\vec{x}_k) - \\vec{w}^T \\vec{x}_k]\n",
        "$$\n",
        "\n",
        "*$\\circ$ Nota: Cuando $D_{train}=\\{ x_k \\in \\mathbb{R} , f(x_k) \\in \\mathbb{R}\\}_{k=1}^N$, al problema se le conoce como regresión lineal simple (en una dimensión).*\n",
        "\n",
        "**Matriz de diseño:**\n",
        "\n",
        "Podemos reescribir el problema usando la matriz que concatena los vectores de características del conjunto de entrenamiento:\n",
        "\n",
        "$$\n",
        "X:= [\\vec{x}_1, … , \\vec{x}_N] \\in \\mathbb{R}^{d \\times N}\n",
        "$$\n",
        "\n",
        "Y definimos también el vector que contiene todas las etiquetas de los datos de entrenamiento:\n",
        "\n",
        "$$\n",
        "\\vec{f}= \\begin{pmatrix}\n",
        "f(\\vec{x}_1) \\\\\n",
        "\\vdots \\\\\n",
        "f(\\vec{x}_N)\n",
        "\\end{pmatrix}\n",
        "\\in \\mathbb{R}^{N}\n",
        "$$\n",
        "\n",
        "Por lo que el estimador (modelo) que contiene todas las predicciones, ahora se escribe como:\n",
        "\n",
        "$$\n",
        "\\widehat{\\vec{f}} = \\begin{pmatrix}\n",
        "\\hat{f}(\\vec{x}_1, \\vec{w}) \\\\\n",
        "\\vdots \\\\\n",
        "\\hat{f}(\\vec{x}_N, \\vec{w})\n",
        "\\end{pmatrix} = X \\vec{w}\n",
        "$$\n",
        "\n",
        "Y la forma analítica de la función costo queda como:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\vec{w}) = \\frac{1}{N} (\\vec{f} - \\widehat{\\vec{f}}) ^T (\\vec{f} - \\widehat{\\vec{f}}) = \\frac{1}{N} \\lVert \\vec{f} - X \\vec{w} \\rVert ^2\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Optimización de la función costo**\n",
        "\n",
        "Siendo que la función costo da una medida del error sobre cómo es la predicción del modelo de regresión con respecto al valor real durante el entrenamiento, buscamos hallar un $\\vec{w}$ que haga a $\\mathcal{L}(\\vec{w})$ tomar su valor mínimo, $\\vec{w}^* = ArgMin _{\\vec{w}} \\{ \\mathcal{L}(\\vec{w}) \\}$.\n",
        "\n",
        "La optimización parte del problema $\\nabla _{\\vec{w}}\\mathcal{L}(\\vec{w}) \\big| _{\\vec{w} = \\vec{w}^*} = \\vec{0}$, de donde se tiene que:\n",
        "\n",
        "$$\n",
        "\\vec{w}^* = (X^T X)^{-1}X^T \\vec{f}\n",
        "$$\n",
        "Por lo que el modelo (hiperplano) entrenado es:\n",
        "\n",
        "$$\n",
        "\\widehat{\\vec{f}}_{\\vec{w}^*}(\\vec{x}) = {\\vec{w}^*} ^T \\vec{x} = [(X^T X)^{-1}X^T \\vec{f}]^T \\vec{x}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Métricas para evaluar modelos de regresión**\n",
        "\n",
        "-  Hasta ahora se ha expuesto como métrica la función costo llamada MSE (*Mean Squared Error* o Error Cuadrático Medio), la cual calcula la media del error entre los valores reales y los predichos:\n",
        "\n",
        "$$\n",
        "MSE= \\frac{1}{N} \\sum _{k=1}^N  [f(\\vec{x}_k) - \\hat{f}(\\vec{x}_k)] ^2 = \\frac{1}{N} \\sum _{k=1}^N (y_k - \\hat{y}_k)^2\n",
        "$$\n",
        "\n",
        "Sin embargo, existen otras métricas, otras funciones de costo para evaluar el rendimiento de un modelo:\n",
        "\n",
        "-   Raíz del Error Cuadrático Medio. Sus unidades, a diferencia de $MSE$, son las mismas que las de las etiquetas y no unidades cuadradas:\n",
        "\n",
        "$$\n",
        "RMSE= \\sqrt{MSE}\n",
        "$$.\n",
        "\n",
        "\n",
        "-   Error Medio Absoluto. Da la medida de qué tan lejos están las predicciones del valor real:\n",
        "\n",
        "$$\n",
        "MAE = \\frac{1}{N} \\sum _{k=1}^N |y_k - \\hat{y}_k|\n",
        "$$\n",
        "\n",
        "-   $R^2$-Score. Dado el error residual $SSR=\\sum _{k=1}^N (y_k - \\hat{y}_k) ^2$ y la varianza total $SST = \\sum _{k=1}^N (y_k - \\overline{y}) ^2$, definimos la métrica $R^2$-Score como:\n",
        "\n",
        " $$\n",
        " R^2 = 1- \\frac{SSR}{SST} \\in [0,1]\n",
        " $$.\n",
        "\n",
        " Esta métrica es el porcentaje de variación explicado por la relación entre $SSR$ y $SST$. Es decir, mide el porcentaje de la variabilidad de la variable objetivo que es explicada por el modelo.\n",
        "\n",
        " Buscamos que $R^2 ≈ 1$, pues se tiene que:\n",
        "\n",
        "$$\n",
        "R^2 =\n",
        "\\begin{cases}\n",
        "1 & \\text{, predicción perfecta} \\\\\n",
        "0 & \\text{, el modelo no explica nada, equivale a predecir el promedio} \\\\\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Puede ocurrir que $R^2 < 0$, lo cual es el peor caso, peor que adivinar el promedio.\n",
        "\n",
        "\n",
        "En scikit-learn $R^2$ es la métrica por default para un modelo (llamémoslo reg) de regresión lineal:\n",
        "\n",
        "    reg.score(X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Regresión lineal en Scikit-learn**\n",
        "\n",
        "Los modelos de regresión tienen la siguiente sintaxis, con la métrica $R^2$ por default:\n",
        "\n",
        "      from sklearn.model_selection import train_test_split\n",
        "      from sklearn.linear_model import LinearRegression\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size, random_state)\n",
        "      reg = LinearRegression()\n",
        "      reg.fit(X_train, y_train)\n",
        "      y_pred = reg.predict(X_test)\n",
        "      reg.score(X_test, y_test) #Métrica R2-score, recibe la matriz de diseño y las etiquetas del conjunto test\n",
        "\n",
        "Para implementar otras métricas:\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "    mse = mean_squared_error(y_test, y_pred) # Métricas\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **Ejemplo: Sklearn Diabetes Dataset**\n",
        "\n",
        "`load_diabetes` en `scikit-learn` es una función que carga un conjunto de datos sintético incluido en esta biblioteca. Es un dataset muy popular para probar algoritmos de regresión.\n",
        "\n",
        "Este\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GA5Og5rrHxkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "diabetes=load_diabetes()\n",
        "\n",
        "# Las funciones .data y .target son atributos específicos de los datasets integrados de scikit-learn\n",
        "X=diabetes.data  # Nos define la matriz de características del dataset diabetes\n",
        "y=diabetes.target  # Nos define el vector de objetivos del dataset diabetes\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"El MSE es:\", mse)\n",
        "print('°°°°°°°°°°°°°°°°°°°')\n",
        "\n",
        "print(\"El R2 score es:\", r2)\n",
        "print('°°°°°°°°°°°°°°°°°°°')\n",
        "\n",
        "print(f'Los pesos del modelo (las entradas del vector de pesos) son: {reg.coef_}')"
      ],
      "metadata": {
        "id": "NA4kIL7RH6q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cae4cca-d324-4519-ef5d-681d73b293c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El MSE es: 2900.193628493482\n",
            "°°°°°°°°°°°°°°°°°°°\n",
            "El R2 score es: 0.4526027629719195\n",
            "°°°°°°°°°°°°°°°°°°°\n",
            "Los pesos del modelo (las entradas del vector de pesos) son: [  37.90402135 -241.96436231  542.42875852  347.70384391 -931.48884588\n",
            "  518.06227698  163.41998299  275.31790158  736.1988589    48.67065743]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Tenemos {diabetes.data.shape[0]} vectores de caracteríticas cuyas entradas son: {diabetes.feature_names}')\n",
        "print(f'Es decir, tenemos una matriz de diseño de orden {diabetes.data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QEdrcpA0-gv",
        "outputId": "ba2c2af4-fb92-42af-e61d-9bdd0aa249d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 442 vectores de caracteríticas cuyas entradas son: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
            "Es decir, tenemos una matriz de diseño de orden (442, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como sería complicado visualizar cómo se ajusta un hiperplano en 10 dimensiones a los datos, vamos a omitir el gráfico."
      ],
      "metadata": {
        "id": "nbbsaoFlJqSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valores reales:\", y_test)\n",
        "print('°°°°°°°°°°°°°°°°°°°')\n",
        "\n",
        "print(\"Valores predichos por el modelo de regresión:\", np.round(y_pred, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_vAeAwV1sKK",
        "outputId": "f5ca946d-3681-4fd5-9555-e1937c810c7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores reales: [219.  70. 202. 230. 111.  84. 242. 272.  94.  96.  94. 252.  99. 297.\n",
            " 135.  67. 295. 264. 170. 275. 310.  64. 128. 232. 129. 118. 263.  77.\n",
            "  48. 107. 140. 113.  90. 164. 180. 233.  42.  84. 172.  63.  48. 108.\n",
            " 156. 168.  90.  52. 200.  87.  90. 258. 136. 158.  69.  72. 171.  95.\n",
            "  72. 151. 168.  60. 122.  52. 187. 102. 214. 248. 181. 110. 140. 202.\n",
            " 101. 222. 281.  61.  89.  91. 186. 220. 237. 233.  68. 190.  96.  72.\n",
            " 153.  98.  37.  63. 184.]\n",
            "°°°°°°°°°°°°°°°°°°°\n",
            "Valores predichos por el modelo de regresión: [139.55 179.52 134.04 291.42 123.79  92.17 258.23 181.34  90.22 108.63\n",
            "  94.14 168.43  53.5  206.63 100.13 130.67 219.53 250.78 196.37 218.58\n",
            " 207.35  88.48  70.43 188.96 154.89 159.36 188.31 180.39  47.99 108.97\n",
            " 174.78  86.36 132.96 184.54 173.83 190.36 124.42 119.65 147.95  59.05\n",
            "  71.62 107.68 165.45 155.01 171.05  61.46  71.67 114.97  51.58 167.58\n",
            " 152.52  62.96 103.5  109.21 175.64 154.6   94.42 210.74 120.26  77.62\n",
            " 187.93 206.49 140.63 105.6  130.7  202.19 171.13 164.91 124.72 144.81\n",
            " 182.   199.41 234.21 145.96  79.87 157.37 192.74 208.9  158.59 206.02\n",
            " 107.48 140.94  54.82  55.93 115.01  78.96  81.56  54.38 166.25]\n"
          ]
        }
      ]
    }
  ]
}